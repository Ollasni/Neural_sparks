"""
Fine-tuned SQL Generator –¥–ª—è –ø—Ä—è–º–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Phi-3 + LoRA –º–æ–¥–µ–ª–∏
–ë–µ–∑ API —Å–µ—Ä–≤–µ—Ä–∞, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–ø—Ä—è–º—É—é —Å –º–æ–¥–µ–ª—å—é
"""

import os
import time
import torch
from typing import Tuple, Dict, List
from pathlib import Path
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º BusinessDictionary –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
class BusinessDictionary:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –±–∏–∑–Ω–µ—Å-—Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    
    def __init__(self):
        self.terms = {
            # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            '–ø—Ä–∏–±—ã–ª—å': 'revenue - costs',
            '–º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å': '(revenue - costs) / revenue * 100',
            '—Å—Ä–µ–¥–Ω–∏–π —á–µ–∫': 'AVG(order_amount)',
            '–≤—ã—Ä—É—á–∫–∞': 'SUM(revenue)',
            '–æ—Å—Ç–∞—Ç–∫–∏': 'current_stock',
            '–æ–±–æ—Ä–æ—Ç': 'SUM(turnover)',
            '—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å': '(profit / revenue) * 100',
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã
            '—Å–µ–≥–æ–¥–Ω—è': 'DATE(created_at) = CURRENT_DATE',
            '–≤—á–µ—Ä–∞': 'DATE(created_at) = CURRENT_DATE - 1',
            '–∑–∞ –Ω–µ–¥–µ–ª—é': 'created_at >= CURRENT_DATE - INTERVAL \'7 days\'',
            '–∑–∞ –º–µ—Å—è—Ü': 'created_at >= CURRENT_DATE - INTERVAL \'30 days\'',
            '–∑–∞ –∫–≤–∞—Ä—Ç–∞–ª': 'created_at >= CURRENT_DATE - INTERVAL \'90 days\'',
            '–∑–∞ –≥–æ–¥': 'created_at >= CURRENT_DATE - INTERVAL \'365 days\'',
            
            # –¢–∞–±–ª–∏—Ü—ã –∏ –ø–æ–ª—è
            '–∑–∞–∫–∞–∑—ã': 'orders',
            '–∫–ª–∏–µ–Ω—Ç—ã': 'customers',
            '–∫–ª–∏–µ–Ω—Ç': 'customer',
            '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏': 'users',
            '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å': 'user',
            '—Ç–æ–≤–∞—Ä—ã': 'products',
            '–ø—Ä–æ–¥–∞–∂–∏': 'sales',
            '—Å–∫–ª–∞–¥': 'inventory',
            '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∏': 'employees',
            '—Ü–µ–Ω–∞': 'price',
            '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ': 'quantity'
        }
        
    def translate_term(self, term: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω –≤ SQL –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é"""
        term_lower = term.lower().strip()
        return self.terms.get(term_lower, term)
    
    def get_related_terms(self, query: str) -> List[str]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–µ –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω—ã –≤ –∑–∞–ø—Ä–æ—Å–µ"""
        found_terms = []
        query_lower = query.lower()
        for term in self.terms.keys():
            if term in query_lower:
                found_terms.append(term)
        return found_terms


class FineTunedSQLGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä SQL –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º fine-tuned Phi-3 + LoRA –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, model_path: str = "finetuning/phi3-mini", adapter_path: str = "finetuning/phi3_bird_lora", 
                 connection_string: str = None, use_dynamic_schema: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è fine-tuned –º–æ–¥–µ–ª–∏
        
        Args:
            model_path: –ü—É—Ç—å –∫ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ Phi-3
            adapter_path: –ü—É—Ç—å –∫ LoRA –∞–¥–∞–ø—Ç–µ—Ä—É
            connection_string: –°—Ç—Ä–æ–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
            use_dynamic_schema: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é —Å—Ö–µ–º—É
        """
        self.model_path = Path(model_path)
        self.adapter_path = Path(adapter_path)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∞–¥–∞–ø—Ç–µ—Ä–∞
        if not self.model_path.exists():
            raise FileNotFoundError(f"–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {self.model_path}")
        
        if not self.adapter_path.exists():
            raise FileNotFoundError(f"LoRA –∞–¥–∞–ø—Ç–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.adapter_path}")
        
        print(f"üîß –ó–∞–≥—Ä—É–∂–∞–µ–º fine-tuned –º–æ–¥–µ–ª—å...")
        print(f"   –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: {self.model_path}")
        print(f"   LoRA –∞–¥–∞–ø—Ç–µ—Ä: {self.adapter_path}")
        
        self._load_model()
        
        # –î–æ–±–∞–≤–ª—è–µ–º business_dict –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å BIGPTAgent
        self.business_dict = BusinessDictionary()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π —Å—Ö–µ–º—ã
        self.use_dynamic_schema = use_dynamic_schema
        self.dynamic_schema_extractor = None
        
        if use_dynamic_schema:
            try:
                from dynamic_schema_extractor import create_dynamic_extractor
                self.dynamic_schema_extractor = create_dynamic_extractor(connection_string)
                print("   ‚úÖ Dynamic schema extractor initialized")
            except ImportError as e:
                print(f"   ‚ö†Ô∏è  Cannot import dynamic schema extractor: {e}")
                self.use_dynamic_schema = False
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Failed to initialize dynamic schema extractor: {e}")
                self.use_dynamic_schema = False
        
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –∞–¥–∞–ø—Ç–µ—Ä"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
            try:
                import torch
                print(f"   üîß PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
            except ImportError:
                raise ImportError("PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install torch")
            
            try:
                from peft import PeftModel
                print("   üîß PEFT –¥–æ—Å—Ç—É–ø–µ–Ω")
            except ImportError:
                raise ImportError("PEFT –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install peft")
            
            try:
                from transformers import AutoModelForCausalLM, AutoTokenizer
                print("   üîß Transformers –¥–æ—Å—Ç—É–ø–µ–Ω")
            except ImportError:
                raise ImportError("Transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install transformers")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
            print("   üìù –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä...")
            self.tokenizer = AutoTokenizer.from_pretrained(str(self.model_path), use_fast=True)
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
            print("   üß† –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å...")
            self.model = AutoModelForCausalLM.from_pretrained(
                str(self.model_path),
                torch_dtype=torch.float16 if torch.backends.mps.is_available() else torch.float32,
                device_map="auto",
                trust_remote_code=True,
                attn_implementation="eager"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º eager attention –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            )
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º LoRA –∞–¥–∞–ø—Ç–µ—Ä
            print("   üîó –ü–æ–¥–∫–ª—é—á–∞–µ–º LoRA –∞–¥–∞–ø—Ç–µ—Ä...")
            self.model = PeftModel.from_pretrained(self.model, str(self.adapter_path))
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ —Ä–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            self.model.eval()
            
            print("   ‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    def generate_sql(self, user_query: str, schema_info: Dict = None) -> Tuple[str, float]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç SQL –∑–∞–ø—Ä–æ—Å –∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞
        
        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
            schema_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ö–µ–º–µ –ë–î (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –¥–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏)
            
        Returns:
            Tuple[str, float]: (SQL –∑–∞–ø—Ä–æ—Å, –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)
        """
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
        prompt = self._create_prompt(user_query)
        
        try:
            # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
            inputs = self.tokenizer(
                prompt, 
                return_tensors="pt", 
                truncation=True, 
                max_length=1024
            )
            
            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
            device = next(self.model.parameters()).device
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            with torch.no_grad():
                try:
                    print(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å –≤—Ö–æ–¥–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏ –¥–ª–∏–Ω–æ–π: {inputs['input_ids'].shape[1]}")
                    
                    outputs = self.model.generate(
                        inputs['input_ids'],
                        attention_mask=inputs.get('attention_mask'),
                        max_new_tokens=40,  # –ï—â–µ –º–µ–Ω—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ñ–æ–∫—É—Å–∞ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–æ–º SQL
                        do_sample=False,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                        pad_token_id=self.tokenizer.pad_token_id,
                        eos_token_id=self.tokenizer.eos_token_id,
                        use_cache=False,
                        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                        num_beams=1,  # Greedy search
                        repetition_penalty=1.05  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π penalty
                    )
                except Exception as cache_error:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å –∫—ç—à–µ–º, –ø—Ä–æ–±—É–µ–º –±–µ–∑ attention_mask: {cache_error}")
                    # Fallback –±–µ–∑ attention_mask
                    outputs = self.model.generate(
                        inputs['input_ids'],
                        max_new_tokens=40,  # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                        do_sample=False,
                        pad_token_id=self.tokenizer.pad_token_id,
                        eos_token_id=self.tokenizer.eos_token_id,
                        use_cache=False,
                        num_beams=1,
                        repetition_penalty=1.05
                    )
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã (–±–µ–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)
            input_length = inputs['input_ids'].shape[1]
            new_tokens = outputs[0][input_length:]
            generated_text = self.tokenizer.decode(new_tokens, skip_special_tokens=True)
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"üîç –í—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {input_length}")
            print(f"üîç –í—ã—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {len(outputs[0])}")
            print(f"üîç –ù–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: {len(new_tokens)}")
            print(f"üìù –ù–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã (–±–µ–∑ –ø—Ä–æ–º–ø—Ç–∞): '{generated_text}'")
            print(f"üîç –î–ª–∏–Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {len(generated_text)}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ SQL –∏–∑ –æ—Ç–≤–µ—Ç–∞ (—Ç–µ–ø–µ—Ä—å –±–µ–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞)
            sql_query = self._extract_sql_from_generated(generated_text)
            
            execution_time = time.time() - start_time
            
            if sql_query:
                print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π SQL: {sql_query}")
            else:
                print("‚ùå SQL –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å")
            
            return sql_query, execution_time
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL: {e}")
            import traceback
            traceback.print_exc()  # –ü–µ—á–∞—Ç–∞–µ–º –ø–æ–ª–Ω—ã–π —Å—Ç–µ–∫—Ç—Ä–µ–π—Å –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            return "", time.time() - start_time
    
    def _extract_sql_from_generated(self, generated_text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç SQL –∏–∑ —É–∂–µ –æ—á–∏—â–µ–Ω–Ω–æ–≥–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–±–µ–∑ –ø—Ä–æ–º–ø—Ç–∞)"""
        try:
            sql_part = generated_text.strip()
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —á—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å
            print(f"üîç –û—Ç–ª–∞–¥–∫–∞: –∏—Å—Ö–æ–¥–Ω—ã–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–¥–ª–∏–Ω–∞ {len(sql_part)}): '{sql_part}'")
            
            # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ - —Å–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º –æ—á–µ–≤–∏–¥–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            primary_stop_words = ['\n\nQuestion', '\n\nDatabase', '\n\nSchema']
            for stop_word in primary_stop_words:
                if stop_word in sql_part:
                    sql_part = sql_part.split(stop_word)[0].strip()
                    print(f"üîç –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è '{stop_word}': '{sql_part}'")
                    break
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫, –∏—â–µ–º –≤–∞–ª–∏–¥–Ω—ã–π SQL —Å—Ä–µ–¥–∏ —Å—Ç—Ä–æ–∫
            if '\n' in sql_part:
                lines = [line.strip() for line in sql_part.split('\n') if line.strip()]
                print(f"üîç –ù–∞–π–¥–µ–Ω—ã —Å—Ç—Ä–æ–∫–∏: {lines}")
                
                valid_commands = ['SELECT', 'DELETE', 'UPDATE', 'INSERT', 'WITH']
                
                # –ò—â–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å SQL –∫–æ–º–∞–Ω–¥—ã
                sql_start_index = -1
                for i, line in enumerate(lines):
                    if any(line.upper().startswith(cmd) for cmd in valid_commands):
                        sql_start_index = i
                        print(f"üîç –ù–∞–π–¥–µ–Ω–∞ SQL —Å—Ç—Ä–æ–∫–∞ –Ω–∞ –ø–æ–∑–∏—Ü–∏–∏ {i}: '{line}'")
                        break
                
                if sql_start_index >= 0:
                    # –°–∫–ª–µ–∏–≤–∞–µ–º SQL —Å—Ç—Ä–æ–∫–∏ –Ω–∞—á–∏–Ω–∞—è —Å –Ω–∞–π–¥–µ–Ω–Ω–æ–π
                    sql_lines = []
                    for i in range(sql_start_index, len(lines)):
                        line = lines[i]
                        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –æ—á–µ–≤–∏–¥–Ω–æ –Ω–µ SQL —Å—Ç—Ä–æ–∫—É
                        if any(stop in line for stop in ['Question:', 'Database:', 'Schema:']):
                            break
                        sql_lines.append(line)
                    
                    sql_part = ' '.join(sql_lines)
                    print(f"üîç –°–∫–ª–µ–µ–Ω–Ω—ã–π SQL: '{sql_part}'")
                else:
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –æ—á–µ–≤–∏–¥–Ω–æ–≥–æ SQL, –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–µ–ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
                    sql_part = lines[0] if lines else sql_part
                    print(f"üîç –í–∑—è—Ç–∞ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞: '{sql_part}'")
            
            # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –≤ –∫–æ–Ω—Ü–µ
            if sql_part.endswith(';'):
                sql_part = sql_part[:-1]
                print(f"üîç –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è ';': '{sql_part}'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ SQL –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ (–±–æ–ª–µ–µ –º—è–≥–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
            sql_keywords = ['SELECT', 'DELETE', 'UPDATE', 'INSERT', 'WITH', 'FROM', 'WHERE', 'ORDER', 'GROUP']
            has_sql_keywords = any(keyword.upper() in sql_part.upper() for keyword in sql_keywords)
            
            if not has_sql_keywords:
                print(f"‚ö†Ô∏è  –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç SQL –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {sql_part[:100]}...")
                
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á—Ç–æ-—Ç–æ –ø–æ—Ö–æ–∂–µ–µ –Ω–∞ SQL –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
                original_lines = [line.strip() for line in generated_text.split('\n') if line.strip()]
                for line in original_lines:
                    if any(keyword.upper() in line.upper() for keyword in sql_keywords):
                        print(f"üîç –ù–∞–π–¥–µ–Ω–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è SQL —Å—Ç—Ä–æ–∫–∞: '{line}'")
                        sql_part = line
                        if sql_part.endswith(';'):
                            sql_part = sql_part[:-1]
                        break
                else:
                    return ""
            
            # –£–±–∏—Ä–∞–µ–º –æ—á–µ–≤–∏–¥–Ω—ã–π –º—É—Å–æ—Ä –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
            cleanup_patterns = [
                'Question:', 'SQL:', 'Database:', 'Schema:', 'Answer:', 'Explanation:',
                'Question', 'Database', 'Schema'
            ]
            
            for pattern in cleanup_patterns:
                if sql_part.startswith(pattern):
                    sql_part = sql_part[len(pattern):].strip()
                    print(f"üîç –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–µ—Ñ–∏–∫—Å–∞ '{pattern}': '{sql_part}'")
            
            # –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ SQL –∫–æ–º–∞–Ω–¥—ã
            valid_commands = ['SELECT', 'DELETE', 'UPDATE', 'INSERT', 'WITH']
            starts_with_valid_command = any(sql_part.upper().startswith(cmd) for cmd in valid_commands)
            
            if not starts_with_valid_command:
                # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—â–µ–º –∫–æ–º–∞–Ω–¥—É –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–æ —Ç–æ–ª—å–∫–æ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ)
                found_cmd = False
                for cmd in valid_commands:
                    # –ò—â–µ–º –∫–æ–º–∞–Ω–¥—É –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ (—Å –ø—Ä–æ–±–µ–ª–∞–º–∏ –∏–ª–∏ –Ω–∞—á–∞–ª–æ–º/–∫–æ–Ω—Ü–æ–º —Å—Ç—Ä–æ–∫–∏)
                    import re
                    pattern = r'\b' + re.escape(cmd.upper()) + r'\b'
                    match = re.search(pattern, sql_part.upper())
                    if match:
                        cmd_index = match.start()
                        sql_part = sql_part[cmd_index:]
                        print(f"üîç –ù–∞–π–¥–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ '{cmd}' –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ –≤ –ø–æ–∑–∏—Ü–∏–∏ {cmd_index}: '{sql_part}'")
                        found_cmd = True
                        break
                
                if not found_cmd:
                    print(f"‚ö†Ô∏è  –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å SQL –∫–æ–º–∞–Ω–¥—ã: '{sql_part[:100]}...'")
                    return ""
            
            # –î–æ–±–∞–≤–ª—è–µ–º LIMIT —Ç–æ–ª—å–∫–æ –¥–ª—è SELECT –∑–∞–ø—Ä–æ—Å–æ–≤
            if sql_part.upper().startswith('SELECT') and 'LIMIT' not in sql_part.upper():
                sql_part += ' LIMIT 1000'
            
            # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è SQL –Ω–∞ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
            validation_error = self._validate_basic_sql(sql_part)
            if validation_error:
                print(f"‚ö†Ô∏è  SQL –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞: {validation_error}")
                return ""
            
            print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π SQL: '{sql_part}'")
            return sql_part
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è SQL –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            return ""
    
    def _get_schema_for_prompt(self) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ö–µ–º—É –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫—É—é –∏–ª–∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫—É—é)"""
        if self.use_dynamic_schema and self.dynamic_schema_extractor:
            try:
                schema = self.dynamic_schema_extractor.get_schema()
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è fine-tuned –º–æ–¥–µ–ª–∏
                lines = []
                for table in schema.tables:
                    table_name = table.name.split('.')[-1] if '.' in table.name else table.name
                    columns_str = ", ".join([
                        f"{col.name} ({col.type})" if col.type else col.name
                        for col in table.columns
                    ])
                    lines.append(f"{table_name}: {columns_str}")
                return "\n".join(lines)
            except Exception as e:
                print(f"‚ö†Ô∏è  Failed to get dynamic schema, falling back to static: {e}")
        
        # Fallback –∫ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–µ–º–µ
        return """customers: id (SERIAL), name (VARCHAR), email (VARCHAR), registration_date (DATE), segment (VARCHAR)
products: id (SERIAL), name (VARCHAR), price (DECIMAL)
orders: id (SERIAL), user_id (INTEGER), product_id (INTEGER), quantity (INTEGER), created_at (TIMESTAMP)
users: id (SERIAL), name (VARCHAR), email (VARCHAR)
sales: id (SERIAL), order_id (INTEGER), product_id (INTEGER), quantity (INTEGER), revenue (DECIMAL), costs (DECIMAL)
inventory: id (SERIAL), product_id (INTEGER), current_stock (INTEGER), warehouse (VARCHAR)"""

    def _create_prompt(self, user_query: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏"""
        # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å—Ö–µ–º—É
        schema = self._get_schema_for_prompt()
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL
        prompt = f"""Database: bi_demo
Schema:
{schema.strip()}

Examples:
Question: –ø–æ–∫–∞–∂–∏ –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
SQL: SELECT * FROM customers LIMIT 1000

Question: –∫–ª–∏–µ–Ω—Ç—ã —Å –∑–∞–∫–∞–∑–∞–º–∏
SQL: SELECT c.name, c.email FROM customers c INNER JOIN orders o ON c.id = o.customer_id LIMIT 1000

Question: {user_query}
SQL:"""
        
        print(f"üîç –°–æ–∑–¥–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–¥–ª–∏–Ω–∞ {len(prompt)}):")
        print(f"'{prompt}'")
        print(f"üîç –ö–æ–Ω–µ—Ü –ø—Ä–æ–º–ø—Ç–∞")
        
        return prompt
    
    def _validate_basic_sql(self, sql: str) -> str:
        """–ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è SQL –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫"""
        try:
            sql_upper = sql.upper()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∞–ª–∏–∞—Å—ã –≤ SELECT –∑–∞–ø—Ä–æ—Å–∞—Ö
            if sql_upper.startswith('SELECT'):
                import re
                
                # –ò—â–µ–º –∞–ª–∏–∞—Å—ã —Ç–∞–±–ª–∏—Ü (TABLE AS ALIAS)
                alias_pattern = r'\b(\w+)\s+AS\s+(\w+)\b'
                aliases = {}
                for match in re.finditer(alias_pattern, sql_upper):
                    table_name = match.group(1)
                    alias_name = match.group(2)
                    aliases[alias_name] = table_name
                
                # –ò—â–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∞–ª–∏–∞—Å–æ–≤ –≤ SELECT –∏ –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö
                select_part = sql_upper.split('FROM')[0] if 'FROM' in sql_upper else sql_upper
                
                # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω ALIAS.COLUMN
                column_refs = re.findall(r'\b([A-Z]\d+)\.', sql_upper)
                
                for alias_ref in set(column_refs):
                    if alias_ref not in aliases:
                        return f"–ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∞–ª–∏–∞—Å '{alias_ref}' –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∑–∞–ø—Ä–æ—Å–µ"
            
            # –î—Ä—É–≥–∏–µ –±–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∑–¥–µ—Å—å
            
            return ""  # –ù–µ—Ç –æ—à–∏–±–æ–∫
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ SQL: {e}")
            return ""  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def _extract_sql(self, generated_text: str, original_prompt: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç SQL –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –£–±–∏—Ä–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            if original_prompt in generated_text:
                sql_part = generated_text.split(original_prompt, 1)[1].strip()
            else:
                sql_part = generated_text.strip()
            
            # –ò—â–µ–º SQL –ø–æ—Å–ª–µ "SQL:" - –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏–º–µ–Ω–Ω–æ –Ω–∞ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            if 'SQL:' in sql_part:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ SQL:
                sql_part = sql_part.split('SQL:', 1)[1].strip()
            
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –Ω–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞—Ö (–≤–∫–ª—é—á–∞—è –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã)
            stop_words = [
                'Question:', 'SQL:', 'Database:', 'Schema:', 'Answer:', 'Explanation:', 
                '\n\n', '\nQuestion', '\nDatabase', '\nSchema', 'Question', 'Database'
            ]
            
            for stop_word in stop_words:
                if stop_word in sql_part:
                    sql_part = sql_part.split(stop_word)[0].strip()
                    break  # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –Ω–∞ –ø–µ—Ä–≤–æ–º –Ω–∞–π–¥–µ–Ω–Ω–æ–º
            
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ –ø—Ä–æ–±–µ–ª–æ–≤
            sql_part = sql_part.strip()
            
            # –£–±–∏—Ä–∞–µ–º —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –≤ –∫–æ–Ω—Ü–µ
            if sql_part.endswith(';'):
                sql_part = sql_part[:-1]
            
            # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ–Ω–æ—Å
            if '\n' in sql_part:
                sql_part = sql_part.split('\n')[0].strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π SQL (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º SELECT, DELETE, UPDATE, INSERT)
            valid_commands = ['SELECT', 'DELETE', 'UPDATE', 'INSERT']
            if not any(sql_part.upper().startswith(cmd) for cmd in valid_commands):
                print(f"‚ö†Ô∏è  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—É—é SQL –∫–æ–º–∞–Ω–¥—É: {sql_part[:100]}...")
                return ""
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –º—É—Å–æ—Ä–∞
            invalid_keywords = ['Question', 'Database', 'Schema', 'Answer']
            for keyword in invalid_keywords:
                if keyword in sql_part:
                    print(f"‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω –º—É—Å–æ—Ä –≤ SQL: {keyword}")
                    return ""
            
            # –î–æ–±–∞–≤–ª—è–µ–º LIMIT —Ç–æ–ª—å–∫–æ –¥–ª—è SELECT –∑–∞–ø—Ä–æ—Å–æ–≤
            if sql_part.upper().startswith('SELECT') and 'LIMIT' not in sql_part.upper():
                sql_part += ' LIMIT 1000'
            
            return sql_part
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è SQL: {e}")
            return ""
    
    def cleanup(self):
        """–û—á–∏—â–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã –º–æ–¥–µ–ª–∏"""
        if hasattr(self, 'model'):
            del self.model
        if hasattr(self, 'tokenizer'):
            del self.tokenizer
        
        # –û—á–∏—â–∞–µ–º –∫—ç—à GPU
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        elif torch.backends.mps.is_available():
            torch.mps.empty_cache()


def test_finetuned_generator():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç fine-tuned –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º fine-tuned SQL –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä...")
    
    try:
        generator = FineTunedSQLGenerator()
        
        test_queries = [
            "–ø–æ–∫–∞–∂–∏ –≤—Å–µ—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤",
            "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫–∞–∑–æ–≤",
            "—Å—Ä–µ–¥–Ω–∏–π —á–µ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤",
            "—Ç–æ–ø 3 –∫–ª–∏–µ–Ω—Ç–∞ –ø–æ –≤—ã—Ä—É—á–∫–µ"
        ]
        
        for query in test_queries:
            print(f"\nüìù –ó–∞–ø—Ä–æ—Å: {query}")
            sql, exec_time = generator.generate_sql(query)
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {exec_time:.2f}—Å")
            print(f"üîç SQL: {sql}")
        
        generator.cleanup()
        print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")


if __name__ == "__main__":
    test_finetuned_generator()
