"""
Query Planner Module for BI-GPT Agent
–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö NL –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω –∑–∞–ø—Ä–æ—Å–∞
–í–∞–ª–∏–¥–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é Pydantic –∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
"""

import json
import logging
from typing import Dict, List, Any, Optional, Union, Literal
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime

from pydantic import BaseModel, Field, validator, root_validator
from pydantic.types import StrictStr, StrictInt, StrictFloat

from nl_normalizer import NormalizedQuery, Language
from retriever import SchemaRetriever, SearchResult

logger = logging.getLogger(__name__)


class AggregationType(str, Enum):
    """–¢–∏–ø—ã –∞–≥—Ä–µ–≥–∞—Ü–∏–π"""
    COUNT = "COUNT"
    SUM = "SUM"
    AVG = "AVG"
    MIN = "MIN"
    MAX = "MAX"
    COUNT_DISTINCT = "COUNT_DISTINCT"


class FilterOperator(str, Enum):
    """–û–ø–µ—Ä–∞—Ç–æ—Ä—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
    EQUALS = "="
    NOT_EQUALS = "!="
    GREATER_THAN = ">"
    GREATER_THAN_OR_EQUAL = ">="
    LESS_THAN = "<"
    LESS_THAN_OR_EQUAL = "<="
    IN = "IN"
    NOT_IN = "NOT IN"
    LIKE = "LIKE"
    NOT_LIKE = "NOT LIKE"
    IS_NULL = "IS NULL"
    IS_NOT_NULL = "IS NOT NULL"
    BETWEEN = "BETWEEN"


class JoinType(str, Enum):
    """–¢–∏–ø—ã —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
    INNER = "INNER"
    LEFT = "LEFT"
    RIGHT = "RIGHT"
    FULL = "FULL"


class SortDirection(str, Enum):
    """–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏"""
    ASC = "ASC"
    DESC = "DESC"


class ColumnReference(BaseModel):
    """–°—Å—ã–ª–∫–∞ –Ω–∞ –∫–æ–ª–æ–Ω–∫—É"""
    table: StrictStr = Field(..., description="–ò–º—è —Ç–∞–±–ª–∏—Ü—ã")
    column: StrictStr = Field(..., description="–ò–º—è –∫–æ–ª–æ–Ω–∫–∏")
    alias: Optional[StrictStr] = Field(None, description="–ü—Å–µ–≤–¥–æ–Ω–∏–º –∫–æ–ª–æ–Ω–∫–∏")
    
    @property
    def full_name(self) -> str:
        """–ü–æ–ª–Ω–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏"""
        return f"{self.table}.{self.column}"
    
    def __str__(self) -> str:
        return self.full_name


class AggregationSpec(BaseModel):
    """–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏"""
    function: AggregationType = Field(..., description="–§—É–Ω–∫—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
    column: ColumnReference = Field(..., description="–ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏")
    alias: Optional[StrictStr] = Field(None, description="–ü—Å–µ–≤–¥–æ–Ω–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
    distinct: bool = Field(False, description="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DISTINCT")
    
    @validator('alias', always=True)
    def generate_alias_if_none(cls, v, values):
        if v is None and 'function' in values and 'column' in values:
            func = values['function'].lower()
            col = values['column'].column
            return f"{func}_{col}"
        return v


class FilterCondition(BaseModel):
    """–£—Å–ª–æ–≤–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏"""
    column: ColumnReference = Field(..., description="–ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
    operator: FilterOperator = Field(..., description="–û–ø–µ—Ä–∞—Ç–æ—Ä —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    value: Union[StrictStr, StrictInt, StrictFloat, List[Any]] = Field(..., description="–ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    logical_operator: Optional[Literal["AND", "OR"]] = Field("AND", description="–õ–æ–≥–∏—á–µ—Å–∫–∏–π –æ–ø–µ—Ä–∞—Ç–æ—Ä —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —É—Å–ª–æ–≤–∏–µ–º")
    
    @validator('value')
    def validate_value_for_operator(cls, v, values):
        if 'operator' in values:
            op = values['operator']
            if op in [FilterOperator.IN, FilterOperator.NOT_IN]:
                if not isinstance(v, list):
                    raise ValueError(f"Operator {op} requires list value")
            elif op == FilterOperator.BETWEEN:
                if not isinstance(v, list) or len(v) != 2:
                    raise ValueError(f"Operator {op} requires list of 2 values")
            elif op in [FilterOperator.IS_NULL, FilterOperator.IS_NOT_NULL]:
                # –î–ª—è NULL –ø—Ä–æ–≤–µ—Ä–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–µ –Ω—É–∂–Ω–æ
                return None
        return v


class JoinSpec(BaseModel):
    """–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
    left_table: StrictStr = Field(..., description="–õ–µ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    right_table: StrictStr = Field(..., description="–ü—Ä–∞–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    left_column: StrictStr = Field(..., description="–ö–æ–ª–æ–Ω–∫–∞ –ª–µ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã")
    right_column: StrictStr = Field(..., description="–ö–æ–ª–æ–Ω–∫–∞ –ø—Ä–∞–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã")
    join_type: JoinType = Field(JoinType.INNER, description="–¢–∏–ø —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è")
    
    @property
    def join_condition(self) -> str:
        """–£—Å–ª–æ–≤–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        return f"{self.left_table}.{self.left_column} = {self.right_table}.{self.right_column}"


class SortSpec(BaseModel):
    """–°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏"""
    column: ColumnReference = Field(..., description="–ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏")
    direction: SortDirection = Field(SortDirection.ASC, description="–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏")


class QueryPlan(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω –∑–∞–ø—Ä–æ—Å–∞"""
    
    # –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    select_columns: List[ColumnReference] = Field(default_factory=list, description="–ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≤—ã–±–æ—Ä–∫–∏")
    aggregations: List[AggregationSpec] = Field(default_factory=list, description="–ê–≥—Ä–µ–≥–∞—Ü–∏–∏")
    from_table: Optional[StrictStr] = Field(None, description="–û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    joins: List[JoinSpec] = Field(default_factory=list, description="–°–æ–µ–¥–∏–Ω–µ–Ω–∏—è")
    filters: List[FilterCondition] = Field(default_factory=list, description="–£—Å–ª–æ–≤–∏—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
    group_by: List[ColumnReference] = Field(default_factory=list, description="–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞")
    having: List[FilterCondition] = Field(default_factory=list, description="–£—Å–ª–æ–≤–∏—è HAVING")
    order_by: List[SortSpec] = Field(default_factory=list, description="–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞")
    limit: Optional[StrictInt] = Field(None, description="–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫")
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    intent: Optional[StrictStr] = Field(None, description="–ù–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    confidence: StrictFloat = Field(1.0, description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø–ª–∞–Ω–µ", ge=0, le=1)
    complexity_score: StrictInt = Field(0, description="–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞", ge=0)
    estimated_performance: Optional[StrictStr] = Field(None, description="–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    
    # –ö–æ–Ω—Ç–µ–∫—Å—Ç
    original_query: Optional[StrictStr] = Field(None, description="–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å")
    normalized_query: Optional[StrictStr] = Field(None, description="–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å")
    language: Optional[Language] = Field(None, description="–Ø–∑—ã–∫ –∑–∞–ø—Ä–æ—Å–∞")
    
    @root_validator
    def validate_query_consistency(cls, values):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–ª–∞–Ω–∞"""
        errors = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –µ—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏
        select_columns = values.get('select_columns', [])
        aggregations = values.get('aggregations', [])
        from_table = values.get('from_table')
        
        if (select_columns or aggregations) and not from_table:
            errors.append("from_table is required when select_columns or aggregations are specified")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É –ø—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        group_by = values.get('group_by', [])
        if aggregations and not group_by:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–≥—Ä–µ–≥–∞—Ü–∏–∏, –Ω–æ –Ω–µ—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –æ–±—ã—á–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            if select_columns:
                errors.append("GROUP BY is required when mixing aggregations with regular columns")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        joins = values.get('joins', [])
        if joins:
            # –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã –≤ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è—Ö –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–≤—è–∑–∞–Ω—ã
            all_tables = {from_table} if from_table else set()
            for join in joins:
                all_tables.add(join.left_table)
                all_tables.add(join.right_table)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã
            for col in select_columns + [agg.column for agg in aggregations]:
                if col.table not in all_tables:
                    errors.append(f"Column {col.full_name} references unknown table {col.table}")
        
        if errors:
            raise ValueError(f"Query plan validation failed: {'; '.join(errors)}")
        
        return values
    
    @validator('complexity_score', always=True)
    def calculate_complexity(cls, v, values):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞"""
        score = 0
        
        # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        score += len(values.get('select_columns', []))
        score += len(values.get('aggregations', [])) * 2
        score += len(values.get('joins', [])) * 3
        score += len(values.get('filters', []))
        score += len(values.get('group_by', []))
        score += len(values.get('having', [])) * 2
        score += len(values.get('order_by', []))
        
        if values.get('limit'):
            score += 1
        
        return score
    
    def get_all_tables(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –≤ –∑–∞–ø—Ä–æ—Å–µ"""
        tables = set()
        
        if self.from_table:
            tables.add(self.from_table)
        
        for join in self.joins:
            tables.add(join.left_table)
            tables.add(join.right_table)
        
        return list(tables)
    
    def get_all_columns(self) -> List[ColumnReference]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ"""
        columns = []
        columns.extend(self.select_columns)
        columns.extend([agg.column for agg in self.aggregations])
        columns.extend([f.column for f in self.filters])
        columns.extend(self.group_by)
        columns.extend([h.column for h in self.having])
        columns.extend([o.column for o in self.order_by])
        
        return columns


class QueryPlanner:
    """–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, schema_retriever: SchemaRetriever):
        self.schema_retriever = schema_retriever
        
        # –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –∫ SQL –æ–ø–µ—Ä–∞—Ü–∏—è–º
        self.intent_mappings = {
            'select': self._plan_select_query,
            'count': self._plan_count_query,
            'aggregate': self._plan_aggregate_query,
            'top': self._plan_top_query,
            'filter': self._plan_filter_query,
            'trend': self._plan_trend_query,
            'compare': self._plan_compare_query
        }
    
    def create_plan(self, normalized_query: NormalizedQuery) -> QueryPlan:
        """–°–æ–∑–¥–∞–µ—Ç –ø–ª–∞–Ω –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        logger.info(f"Creating query plan for: {normalized_query.normalized}")
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å –±–∞–∑–æ–≤–æ–≥–æ –ø–ª–∞–Ω–∞
        plan = QueryPlan(
            original_query=normalized_query.original,
            normalized_query=normalized_query.normalized,
            language=normalized_query.detected_language,
            intent=normalized_query.intent,
            confidence=normalized_query.confidence
        )
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü
        relevant_tables = self._identify_tables(normalized_query)
        relevant_columns = self._identify_columns(normalized_query, relevant_tables)
        
        if not relevant_tables:
            logger.warning("No relevant tables found")
            return plan
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        plan.from_table = relevant_tables[0]
        
        # –ü–ª–∞–Ω–∏—Ä—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—Ü
        if len(relevant_tables) > 1:
            plan.joins = self._plan_joins(relevant_tables)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        if normalized_query.intent in self.intent_mappings:
            planner_func = self.intent_mappings[normalized_query.intent]
            plan = planner_func(plan, normalized_query, relevant_columns)
        else:
            # –ë–∞–∑–æ–≤–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
            plan = self._plan_default_query(plan, normalized_query, relevant_columns)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –¥–∞—Ç–∞–º
        plan = self._add_date_filters(plan, normalized_query)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–º–∏—Ç—ã –ø–æ —á–∏—Å–ª–∞–º
        plan = self._add_number_limits(plan, normalized_query)
        
        logger.info(f"Created plan with complexity score: {plan.complexity_score}")
        return plan
    
    def _identify_tables(self, normalized_query: NormalizedQuery) -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã"""
        # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—ã —á–µ—Ä–µ–∑ —Ä–µ—Ç—Ä–∏–≤–µ—Ä
        search_results = self.schema_retriever.search(
            normalized_query.normalized, 
            search_type="tables", 
            limit=5
        )
        
        tables = []
        for result in search_results:
            if result.result_type == "table":
                table_name = result.metadata.get('name', '')
                if table_name and table_name not in tables:
                    tables.append(table_name)
        
        # –¢–∞–∫–∂–µ –∏—â–µ–º –ø–æ –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω–∞–º
        for term in normalized_query.business_terms:
            term_search = self.schema_retriever.search(term, search_type="tables", limit=3)
            for result in term_search:
                if result.result_type == "table":
                    table_name = result.metadata.get('name', '')
                    if table_name and table_name not in tables:
                        tables.append(table_name)
        
        return tables[:3]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 3 —Ç–∞–±–ª–∏—Ü–∞–º–∏
    
    def _identify_columns(self, normalized_query: NormalizedQuery, tables: List[str]) -> List[ColumnReference]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏"""
        columns = []
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ —á–µ—Ä–µ–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
        search_results = self.schema_retriever.search(
            normalized_query.normalized,
            search_type="columns",
            limit=10
        )
        
        for result in search_results:
            if result.result_type == "column":
                table_name = result.metadata.get('table', '')
                column_name = result.metadata.get('name', '')
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∞ –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                if any(table in table_name for table in tables):
                    col_ref = ColumnReference(
                        table=table_name,
                        column=column_name
                    )
                    if col_ref not in columns:
                        columns.append(col_ref)
        
        return columns
    
    def _plan_joins(self, tables: List[str]) -> List[JoinSpec]:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –º–µ–∂–¥—É —Ç–∞–±–ª–∏—Ü–∞–º–∏"""
        joins = []
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è–º –æ—Ç —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞
        suggested_joins = self.schema_retriever.suggest_joins(tables)
        
        for join_info in suggested_joins:
            # –ü–∞—Ä—Å–∏–º –∏–º–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü –∏ –∫–æ–ª–æ–Ω–æ–∫
            from_parts = join_info['join_condition'].split(' = ')
            if len(from_parts) == 2:
                left_part = from_parts[0].strip()
                right_part = from_parts[1].strip()
                
                if '.' in left_part and '.' in right_part:
                    left_table, left_col = left_part.rsplit('.', 1)
                    right_table, right_col = right_part.rsplit('.', 1)
                    
                    join_spec = JoinSpec(
                        left_table=left_table,
                        right_table=right_table,
                        left_column=left_col,
                        right_column=right_col,
                        join_type=JoinType.INNER
                    )
                    joins.append(join_spec)
        
        return joins
    
    def _plan_select_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –æ–±—ã—á–Ω—ã–π SELECT –∑–∞–ø—Ä–æ—Å"""
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        plan.select_columns = columns[:10]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        return plan
    
    def _plan_count_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç COUNT –∑–∞–ø—Ä–æ—Å"""
        # –î–ª—è count –∑–∞–ø—Ä–æ—Å–æ–≤ —Å–æ–∑–¥–∞–µ–º –∞–≥—Ä–µ–≥–∞—Ü–∏—é
        if plan.from_table:
            # –ò—â–µ–º –ø–æ–¥—Ö–æ–¥—è—â—É—é –∫–æ–ª–æ–Ω–∫—É –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ (–æ–±—ã—á–Ω–æ ID)
            count_column = None
            for col in columns:
                if 'id' in col.column.lower() or col.column.lower().endswith('_id'):
                    count_column = col
                    break
            
            if not count_column and columns:
                count_column = columns[0]
            
            if count_column:
                plan.aggregations.append(AggregationSpec(
                    function=AggregationType.COUNT,
                    column=count_column,
                    alias="count"
                ))
        
        return plan
    
    def _plan_aggregate_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∞–≥—Ä–µ–≥–∞—Ü–∏–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å"""
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É
        text = normalized_query.normalized.lower()
        
        for col in columns:
            col_tags = []
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–æ–Ω–∫–µ –∏–∑ —Å—Ö–µ–º—ã
            for table_name, table_info in self.schema_retriever.table_index.items():
                if col.table in table_name:
                    for column_info in self.schema_retriever.column_index.values():
                        if column_info['table'] == table_name and column_info['name'] == col.column:
                            col_tags = column_info.get('tags', [])
                            break
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–≥—Ä–µ–≥–∞—Ü–∏—é –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
            if '—Å—É–º–º–∞' in text or 'sum' in text or '–∏—Ç–æ–≥–æ' in text:
                if 'money' in col_tags or 'measure' in col_tags:
                    plan.aggregations.append(AggregationSpec(
                        function=AggregationType.SUM,
                        column=col,
                        alias=f"sum_{col.column}"
                    ))
            elif '—Å—Ä–µ–¥–Ω–µ–µ' in text or '—Å—Ä–µ–¥–Ω–∏–π' in text or 'avg' in text:
                if 'money' in col_tags or 'measure' in col_tags:
                    plan.aggregations.append(AggregationSpec(
                        function=AggregationType.AVG,
                        column=col,
                        alias=f"avg_{col.column}"
                    ))
            elif '–º–∞–∫—Å–∏–º—É–º' in text or 'max' in text:
                plan.aggregations.append(AggregationSpec(
                    function=AggregationType.MAX,
                    column=col,
                    alias=f"max_{col.column}"
                ))
            elif '–º–∏–Ω–∏–º—É–º' in text or 'min' in text:
                plan.aggregations.append(AggregationSpec(
                    function=AggregationType.MIN,
                    column=col,
                    alias=f"min_{col.column}"
                ))
        
        return plan
    
    def _plan_top_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç TOP –∑–∞–ø—Ä–æ—Å"""
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏
        plan.select_columns = columns[:5]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–∏–º–∏—Ç –∏–∑ —á–∏—Å–µ–ª
        for number_info in normalized_query.extracted_numbers:
            if number_info['value'] <= 100:  # –†–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç
                plan.limit = int(number_info['value'])
                break
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ
        if columns:
            # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ (–æ–±—ã—á–Ω–æ —Å —Ç–µ–≥–æ–º money/measure)
            sort_column = None
            for col in columns:
                col_info = self.schema_retriever.column_index.get(col.full_name, {})
                col_tags = col_info.get('tags', [])
                if 'money' in col_tags or 'measure' in col_tags:
                    sort_column = col
                    break
            
            if not sort_column:
                sort_column = columns[0]
            
            plan.order_by.append(SortSpec(
                column=sort_column,
                direction=SortDirection.DESC
            ))
        
        return plan
    
    def _plan_filter_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        plan.select_columns = columns
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∏—Å–µ–ª –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        text = normalized_query.normalized.lower()
        
        for col in columns:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
            if '–±–æ–ª—å—à–µ' in text or '—Å–≤—ã—à–µ' in text:
                for number_info in normalized_query.extracted_numbers:
                    plan.filters.append(FilterCondition(
                        column=col,
                        operator=FilterOperator.GREATER_THAN,
                        value=number_info['value']
                    ))
                    break
            elif '–º–µ–Ω—å—à–µ' in text or '–º–µ–Ω–µ–µ' in text:
                for number_info in normalized_query.extracted_numbers:
                    plan.filters.append(FilterCondition(
                        column=col,
                        operator=FilterOperator.LESS_THAN,
                        value=number_info['value']
                    ))
                    break
        
        return plan
    
    def _plan_trend_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤"""
        # –î–ª—è —Ç—Ä–µ–Ω–¥–æ–≤ –Ω—É–∂–Ω–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        date_columns = []
        measure_columns = []
        
        for col in columns:
            col_info = self.schema_retriever.column_index.get(col.full_name, {})
            col_tags = col_info.get('tags', [])
            
            if 'date' in col_tags or 'time' in col_tags:
                date_columns.append(col)
            elif 'money' in col_tags or 'measure' in col_tags:
                measure_columns.append(col)
        
        if date_columns and measure_columns:
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
            plan.group_by = date_columns[:1]
            plan.select_columns = date_columns[:1]
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –º–µ—Ä—ã
            for measure_col in measure_columns[:2]:
                plan.aggregations.append(AggregationSpec(
                    function=AggregationType.SUM,
                    column=measure_col,
                    alias=f"sum_{measure_col.column}"
                ))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
            plan.order_by.append(SortSpec(
                column=date_columns[0],
                direction=SortDirection.ASC
            ))
        
        return plan
    
    def _plan_compare_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        # –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω—É–∂–Ω–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞
        category_columns = []
        measure_columns = []
        
        for col in columns:
            col_info = self.schema_retriever.column_index.get(col.full_name, {})
            col_tags = col_info.get('tags', [])
            
            if 'category' in col_tags or 'status' in col_tags:
                category_columns.append(col)
            elif 'money' in col_tags or 'measure' in col_tags:
                measure_columns.append(col)
        
        if category_columns and measure_columns:
            plan.group_by = category_columns[:2]
            plan.select_columns = category_columns[:2]
            
            for measure_col in measure_columns[:2]:
                plan.aggregations.append(AggregationSpec(
                    function=AggregationType.SUM,
                    column=measure_col,
                    alias=f"sum_{measure_col.column}"
                ))
        
        return plan
    
    def _plan_default_query(self, plan: QueryPlan, normalized_query: NormalizedQuery, columns: List[ColumnReference]) -> QueryPlan:
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        plan.select_columns = columns[:8]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫
        return plan
    
    def _add_date_filters(self, plan: QueryPlan, normalized_query: NormalizedQuery) -> QueryPlan:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –¥–∞—Ç–∞–º"""
        if not normalized_query.extracted_dates:
            return plan
        
        # –ò—â–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–∞–º–∏
        date_columns = []
        for col in plan.get_all_columns():
            col_info = self.schema_retriever.column_index.get(col.full_name, {})
            col_tags = col_info.get('tags', [])
            if 'date' in col_tags or 'time' in col_tags:
                date_columns.append(col)
        
        if not date_columns:
            return plan
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–µ—Ä–≤–æ–π –Ω–∞–π–¥–µ–Ω–Ω–æ–π –¥–∞—Ç–µ
        date_column = date_columns[0]
        for date_info in normalized_query.extracted_dates:
            if date_info['type'] == 'relative_date':
                plan.filters.append(FilterCondition(
                    column=date_column,
                    operator=FilterOperator.GREATER_THAN_OR_EQUAL,
                    value=date_info['sql_expression']
                ))
            elif date_info['type'] == 'absolute_date':
                plan.filters.append(FilterCondition(
                    column=date_column,
                    operator=FilterOperator.EQUALS,
                    value=date_info['sql_expression']
                ))
        
        return plan
    
    def _add_number_limits(self, plan: QueryPlan, normalized_query: NormalizedQuery) -> QueryPlan:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏–º–∏—Ç—ã –ø–æ —á–∏—Å–ª–∞–º"""
        if not normalized_query.extracted_numbers:
            return plan
        
        # –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ –µ—Å—Ç—å "—Ç–æ–ø", "–ª—É—á—à–∏–µ" –∏ —á–∏—Å–ª–æ, –¥–æ–±–∞–≤–ª—è–µ–º LIMIT
        text = normalized_query.normalized.lower()
        if any(word in text for word in ['—Ç–æ–ø', '–ª—É—á—à–∏–µ', 'top', 'best', '–ø–µ—Ä–≤—ã–µ']):
            for number_info in normalized_query.extracted_numbers:
                if number_info['value'] <= 100:  # –†–∞–∑—É–º–Ω—ã–π –ª–∏–º–∏—Ç
                    plan.limit = int(number_info['value'])
                    break
        
        return plan


def main():
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞"""
    import argparse
    from nl_normalizer import NLNormalizer
    
    parser = argparse.ArgumentParser(description='Query Planner Test')
    parser.add_argument('--query', type=str, required=True, help='Query to plan')
    parser.add_argument('--schema', type=str, default='schema.json', help='Schema file')
    parser.add_argument('--verbose', action='store_true', help='Enable verbose logging')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    normalizer = NLNormalizer()
    retriever = SchemaRetriever(args.schema)
    planner = QueryPlanner(retriever)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
    normalized_query = normalizer.normalize(args.query)
    
    # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω
    plan = planner.create_plan(normalized_query)
    
    print(f"üî§ Original query: {plan.original_query}")
    print(f"‚ú® Normalized query: {plan.normalized_query}")
    print(f"üéØ Intent: {plan.intent}")
    print(f"üìä Complexity score: {plan.complexity_score}")
    print(f"üî¢ Confidence: {plan.confidence:.3f}")
    print()
    
    print("üìã Query Plan:")
    print(f"  FROM: {plan.from_table}")
    
    if plan.select_columns:
        print(f"  SELECT:")
        for col in plan.select_columns:
            print(f"    - {col.full_name}")
    
    if plan.aggregations:
        print(f"  AGGREGATIONS:")
        for agg in plan.aggregations:
            print(f"    - {agg.function}({agg.column.full_name}) AS {agg.alias}")
    
    if plan.joins:
        print(f"  JOINS:")
        for join in plan.joins:
            print(f"    - {join.join_type} JOIN {join.right_table} ON {join.join_condition}")
    
    if plan.filters:
        print(f"  WHERE:")
        for filter_cond in plan.filters:
            print(f"    - {filter_cond.column.full_name} {filter_cond.operator} {filter_cond.value}")
    
    if plan.group_by:
        print(f"  GROUP BY:")
        for col in plan.group_by:
            print(f"    - {col.full_name}")
    
    if plan.order_by:
        print(f"  ORDER BY:")
        for sort_spec in plan.order_by:
            print(f"    - {sort_spec.column.full_name} {sort_spec.direction}")
    
    if plan.limit:
        print(f"  LIMIT: {plan.limit}")
    
    # –í—ã–≤–æ–¥–∏–º JSON –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    if args.verbose:
        print("\nüìÑ JSON Plan:")
        print(json.dumps(plan.dict(), indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
